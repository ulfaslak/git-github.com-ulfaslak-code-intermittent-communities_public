{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# **Preamble**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T21:21:57.543291Z",
     "start_time": "2017-10-08T21:21:57.226180Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib as mpl\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import re\n",
    "import itertools\n",
    "import mmh3\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime as dt\n",
    "from datetime import time\n",
    "from random import randrange, gauss, shuffle\n",
    "import networkx as nx\n",
    "import community\n",
    "from collections import defaultdict\n",
    "from datetime import datetime as dt\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import triu\n",
    "import scipy\n",
    "from dateutil import tz\n",
    "import datetime\n",
    "from scipy.optimize import curve_fit\n",
    "from random import choice, sample\n",
    "from shapely.geometry import Polygon\n",
    "import mahotas\n",
    "from ulf import ulf\n",
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set layout parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T21:21:58.021583Z",
     "start_time": "2017-10-08T21:21:57.942385Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use([\"classic\"])\n",
    "np.set_printoptions(precision=4)\n",
    "np.core.arrayprint._line_width = 100\n",
    "\n",
    "def standarize_plot_parameters():\n",
    "    # http://scipy.github.io/old-wiki/pages/Cookbook/Matplotlib/LaTeX_Examples\n",
    "    # thesis has 417.47 points in column size, with 0.6\\columnwidth\n",
    "    fig_width_pt = 417.47*0.6\n",
    "    inches_per_pt = 1.0/72.27               # Convert pt to inches\n",
    "    golden_mean = (np.sqrt(5)-1.0)/2.0         # Aesthetic ratio\n",
    "    fig_width = fig_width_pt*inches_per_pt  # width in inches\n",
    "    fig_height = fig_width*golden_mean       # height in inches\n",
    "    params = {\n",
    "        'axes.labelsize': 10,\n",
    "        'legend.fontsize': 7,\n",
    "        'xtick.labelsize': 8,\n",
    "        'ytick.labelsize': 8,\n",
    "        'figure.figsize': [fig_width, fig_height],\n",
    "        'font.family': 'STIXGeneral',  # close enough to LaTeX font\n",
    "        'font.size': 8,\n",
    "        'figure.frameon': False\n",
    "    }\n",
    "    plt.rcParams.update(params)\n",
    "\n",
    "standarize_plot_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T21:21:58.904896Z",
     "start_time": "2017-10-08T21:21:58.895280Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def naive(arr, stat):\n",
    "    try:\n",
    "        return stat(arr)\n",
    "    except ValueError:\n",
    "        return -1\n",
    "    \n",
    "def load_binned_network(kind, filename):\n",
    "    with open('data/processed_data/binned_networks/'+kind+'/'+filename+'.pkl', 'r') as infile:\n",
    "        return pickle.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T21:22:00.265440Z",
     "start_time": "2017-10-08T21:22:00.160398Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def build_adjacency_tensor(layers, index=\"zero\"):\n",
    "    nodes = set([\n",
    "        n\n",
    "        for l in layers\n",
    "        for n in list(l['user1']) + list(l['user2'])\n",
    "    ])\n",
    "    \n",
    "    ind = dict((n, i) for i, n in enumerate(nodes))\n",
    "    \n",
    "    A = defaultdict(int)\n",
    "    for l, layer in enumerate(layers):\n",
    "        for _, row in layer.iterrows():\n",
    "            # Must add both ways if undirected so A becomes symmetrical. If only added one-way\n",
    "            # triu will only be connections from 'user' and and tril from 'bt_mac' or vice versa.\n",
    "            if index == \"zero\":\n",
    "                A[(ind[row['user1']], ind[row['user2']], l)] += 1\n",
    "                A[(ind[row['user2']], ind[row['user1']], l)] += 1\n",
    "            else:\n",
    "                A[(row['user1'], row['user2'], l)] += 1\n",
    "                A[(row['user2'], row['user1'], l)] += 1\n",
    "    return A\n",
    "\n",
    "def write_pajek(A, node_labels=None, index_from=0):\n",
    "    \"\"\"Return multiplex representation of multiplex network adjacency matrix A\n",
    "    \n",
    "    Providing an adjacency tensor where A[:, :, k] is adjacency matrix of temporal\n",
    "    layer k, return a pajek format representation of the temporal network which weights interlayer\n",
    "    edges by state node neighborhood similarity. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A : numpy.3darray\n",
    "        3d tensor where each A[:, :, k] is a layer adjacency matrix\n",
    "    node_labels : list\n",
    "        List of node labels if (optional)\n",
    "    index_from : int\n",
    "        From which number to index nodes and layers in pajek format from (default=0)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : string\n",
    "        A network string in pajek format\n",
    "    \"\"\"\n",
    "    \n",
    "    def _write_outfile(A):\n",
    "        \"\"\"Write nodes and intra/inter-edges from A and J to string.\"\"\"\n",
    "        def __remove_symmetry_A(A):\n",
    "            A_triu = defaultdict(int)\n",
    "            for (i, j, k), w in A.items():\n",
    "                if j > i:\n",
    "                    A_triu[(i, j, k)] = w\n",
    "            return A_triu\n",
    "        def __write_nodes(outfile):\n",
    "            outfile += \"*Vertices %d\" % Nn\n",
    "            for nid, label in enumerate(nodes):\n",
    "                outfile += '\\n%d \"%s\" 1.0' % (nid + index_from, str(label))\n",
    "            return outfile\n",
    "        def __write_intra_edges(outfile):\n",
    "            outfile += \"\\n*Intra\\n# layer node node [weight]\"\n",
    "            for (i, j, k), w in __remove_symmetry_A(A).items():\n",
    "                outfile += '\\n%d %d %d %f' % (\n",
    "                    k + index_from,  # layer\n",
    "                    nodemap[i] + index_from,  # node\n",
    "                    nodemap[j] + index_from,  # node\n",
    "                    w                # weight\n",
    "                )\n",
    "            return outfile\n",
    "        \n",
    "        outfile = \"\"\n",
    "        outfile = __write_nodes(outfile)\n",
    "        outfile = __write_intra_edges(outfile)\n",
    "        \n",
    "        return outfile\n",
    "    \n",
    "    nodes = sorted(set([n for i, j, _ in A.keys() for n in [i, j]]))\n",
    "    Nn = len(nodes)\n",
    "    Nl = len(set([k for i, j, k in A.keys()]))\n",
    "    \n",
    "    nodemap = dict(zip(nodes, range(Nn)))\n",
    "\n",
    "    return _write_outfile(A)\n",
    "    \n",
    "def community_members(layer_commu):\n",
    "    commu_members = defaultdict(set)\n",
    "    for l, layer_partition in layer_commu.items():\n",
    "        for c, nodes in layer_partition.items():\n",
    "            commu_members[c].update(nodes)\n",
    "    return commu_members"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load and preprocess**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Sensible DTU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T21:26:19.779186Z",
     "start_time": "2017-10-08T21:26:16.041379Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Load\n",
    "network_sensibleDTU = load_binned_network('1month_data_new','10mins_short_new'); fof = 2\n",
    "\n",
    "# Make slices for a span of days (e.g. monday to friday)\n",
    "spd = 288 / fof  # slices per day\n",
    "dow = 0\n",
    "\n",
    "network1 = [\n",
    "    l\n",
    "    for d in range(0, 5)\n",
    "    for l in network_sensibleDTU[spd*(dow+5+d):spd*(dow+6+d)]\n",
    "]\n",
    "\n",
    "# Null out layers in non-work hours\n",
    "# network1 = [\n",
    "#     df if 8 <= (l%144)/6 <= 17 else \n",
    "#     pd.DataFrame(columns = ['timestamp', 'user1', 'user2'])\n",
    "#     for l, df in enumerate(network1)\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Workplace*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T21:24:04.298390Z",
     "start_time": "2017-10-08T21:24:03.398463Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "network_workplace = pd.read_csv(\"data/workplace/tij_InVS.txt\", delimiter=\" \", names=[\"timestamp\", 'user1', 'user2']); fof = 2\n",
    "\n",
    "# Minimum timestamp is a thursday\n",
    "print dt.fromtimestamp(network_workplace['timestamp'].min()).weekday()\n",
    "\n",
    "# Shift data by 4 days to make first day a monday\n",
    "network_workplace['timestamp'] = np.array([dt.fromtimestamp(ts - 3600) for ts in (network_workplace['timestamp'] + 86400 * 4)])\n",
    "\n",
    "# Layer width in minutes\n",
    "layer_size = 10\n",
    "\n",
    "# Layer time bins from lower of first to (and including) upper of last\n",
    "lower_bin = int(network_workplace['timestamp'].min().date().strftime(\"%s\"))\n",
    "upper_bin = lower_bin + 86400*5# int(network_workplace['timestamp'].max().date().strftime(\"%s\")) + 86400\n",
    "bins = [\n",
    "    dt.fromtimestamp(ts)\n",
    "    for ts in np.arange(lower_bin, upper_bin+layer_size*60, layer_size*60)\n",
    "]\n",
    "\n",
    "# List of pandas dataframes, each a temporal network layer\n",
    "network2 = [\n",
    "    network_workplace[(network_workplace['timestamp'] > low) & (network_workplace['timestamp'] < high)]\n",
    "    for low, high in zip(bins[:-1], bins[1:])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensible DTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T21:26:44.945122Z",
     "start_time": "2017-10-08T21:26:19.781447Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "layer_indices1 = [l for l, n in enumerate(network1) if n.shape[0] > 0]\n",
    "A1 = build_adjacency_tensor([n for n in network1 if n.shape[0] > 0], index=None)\n",
    "network_pajek1 = write_pajek(A1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T21:30:17.635571Z",
     "start_time": "2017-10-08T21:26:44.947256Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "_, layer_commu_pred1_FC_, _, _ = ulf.Infomap(\n",
    "    network_pajek1,\n",
    "    '-i', 'multiplex',\n",
    "    '--multiplex-relax-rate', '0.25',\n",
    "    '--overlapping',\n",
    "    '--expanded',\n",
    "    '--clu',\n",
    "    '--two-level',\n",
    "    '-z',\n",
    "    'pid%d' % random.randint(0, 1000000)\n",
    ")\n",
    "layer_commu_pred1_FC_ = dict((layer_indices1[k], v) for k, v in layer_commu_pred1_FC_.items())\n",
    "\n",
    "# Remove nodes that don't actually belong in layer\n",
    "nodes_l = defaultdict(set)\n",
    "for l, n in enumerate(network1):\n",
    "    nodes = set(n.user1) | set(n.user2)\n",
    "    nodes_l[l] = list(nodes)\n",
    "nodes_l = ulf.default_to_regular(nodes_l)\n",
    "\n",
    "tmp = defaultdict(lambda: defaultdict(list))\n",
    "for l, c_nodes in layer_commu_pred1_FC_.items():\n",
    "    for c, nodes in c_nodes.items():\n",
    "        if len(set(nodes) & set(nodes_l[l])) != 0:\n",
    "            tmp[l][c].extend([n for n in nodes if n in nodes_l[l]])\n",
    "            \n",
    "layer_commu_pred1_FC = ulf.default_to_regular(tmp)\n",
    "communities_pred1_FC = ulf.default_to_regular(community_members(layer_commu_pred1_FC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T21:32:32.638056Z",
     "start_time": "2017-10-08T21:30:17.638057Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "_, layer_commu_pred1_NFC, _, _ = ulf.Infomap(\n",
    "    network_pajek1,\n",
    "    '-i', 'multiplex',\n",
    "    '--multiplex-js-relax-rate', '0.25',\n",
    "    '--overlapping',\n",
    "    '--expanded',\n",
    "    '--clu',\n",
    "    '--two-level',\n",
    "    '-z',\n",
    "    'pid%d' % random.randint(0, 1000000)\n",
    ")\n",
    "layer_commu_pred1_NFC = dict((layer_indices1[k], v) for k, v in layer_commu_pred1_NFC.items())\n",
    "communities_pred1_NFC = ulf.default_to_regular(community_members(layer_commu_pred1_NFC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T21:32:33.369014Z",
     "start_time": "2017-10-08T21:32:32.640504Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "layer_indices2 = [l for l, n in enumerate(network2) if n.shape[0] > 0]\n",
    "A2 = build_adjacency_tensor([n for n in network2 if n.shape[0] > 0], index=None)\n",
    "network_pajek2 = write_pajek(A2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T21:32:33.922981Z",
     "start_time": "2017-10-08T21:32:33.371243Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "_, layer_commu_pred2_FC_, _, _ = ulf.Infomap(\n",
    "    network_pajek2,\n",
    "    '-i', 'multiplex',\n",
    "    '--multiplex-relax-rate', '0.25',\n",
    "    '--overlapping',\n",
    "    '--expanded',\n",
    "    '--clu',\n",
    "    '--two-level',\n",
    "    '-z',\n",
    "    'pid%d' % random.randint(0, 1000000)\n",
    ")\n",
    "layer_commu_pred2_FC_ = dict((layer_indices2[k], v) for k, v in layer_commu_pred2_FC_.items())\n",
    "\n",
    "# Remove nodes that don't actually belong in layer\n",
    "nodes_l = defaultdict(set)\n",
    "for l, n in enumerate(network2):\n",
    "    nodes = set(n.user1) | set(n.user2)\n",
    "    nodes_l[l] = list(nodes)\n",
    "nodes_l = ulf.default_to_regular(nodes_l)\n",
    "\n",
    "tmp = defaultdict(lambda: defaultdict(list))\n",
    "for l, c_nodes in layer_commu_pred2_FC_.items():\n",
    "    for c, nodes in c_nodes.items():\n",
    "        if len(set(nodes) & set(nodes_l[l])) != 0:\n",
    "            tmp[l][c].extend([n for n in nodes if n in nodes_l[l]])\n",
    "            \n",
    "layer_commu_pred2_FC = ulf.default_to_regular(tmp)\n",
    "communities_pred2_FC = ulf.default_to_regular(community_members(layer_commu_pred2_FC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T21:32:34.208913Z",
     "start_time": "2017-10-08T21:32:33.925505Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "_, layer_commu_pred2_NFC, _, _ = ulf.Infomap(\n",
    "    network_pajek2,\n",
    "    '-i', 'multiplex',\n",
    "    '--multiplex-js-relax-rate', '0.25',\n",
    "    '--overlapping',\n",
    "    '--expanded',\n",
    "    '--clu',\n",
    "    '--two-level',\n",
    "    '-z',\n",
    "    'pid%d' % random.randint(0, 1000000)\n",
    ")\n",
    "layer_commu_pred2_NFC = dict((layer_indices2[k], v) for k, v in layer_commu_pred2_NFC.items())\n",
    "communities_pred2_NFC = ulf.default_to_regular(community_members(layer_commu_pred2_NFC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Save for visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T21:58:28.255903Z",
     "start_time": "2017-10-08T21:58:28.049453Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def fill_polygon(poly, m=1):\n",
    "    \"\"\"Return polygon as grid of points inside polygon.\n",
    "\n",
    "    Input : poly (list of lists)\n",
    "    Output : output (list of lists)\n",
    "    \"\"\"\n",
    "    xs, ys = zip(*poly)\n",
    "    \n",
    "    minx, maxx = min(xs), max(xs)\n",
    "    miny, maxy = min(ys), max(ys)\n",
    "    \n",
    "    X = int((maxx - minx + 1) * m)\n",
    "    Y = int((maxy - miny + 1) * m)\n",
    "\n",
    "    grid = np.ones((X, Y), dtype=np.int8)\n",
    "\n",
    "    return set([\n",
    "        (x/float(m) + minx - 2, y/float(m) + miny)\n",
    "        for (x, y) in zip(*np.nonzero(grid))\n",
    "    ]) | set([\n",
    "        (x/float(m) + minx + 2, y/float(m) + miny)\n",
    "        for (x, y) in zip(*np.nonzero(grid))\n",
    "    ])\n",
    "\n",
    "def all_points_in_blocks(com_blocks, m=1):\n",
    "    points = set(\n",
    "        [\n",
    "            tuple(point)\n",
    "            for block in com_blocks \n",
    "            for point in fill_polygon(block['points'], m=m)\n",
    "        ]\n",
    "    ) \n",
    "    perifery = set(\n",
    "        [\n",
    "            tuple(point)\n",
    "            for block in com_blocks \n",
    "            for point in block['points']\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return points | perifery\n",
    "\n",
    "def ordered_set(seq):\n",
    "    _seq = seq[:2]\n",
    "    for x in seq[2:]:\n",
    "        if (_seq[-2][0] == _seq[-1][0]) & (x[0] == _seq[-1][0]):\n",
    "            _seq[-1] = x\n",
    "        else:\n",
    "            _seq.append(x)\n",
    "    return _seq\n",
    "\n",
    "def translate_blocks(com_blocks, dx=0):\n",
    "    return [\n",
    "        {\n",
    "            'c': block['c'],\n",
    "            'points': [\n",
    "                [point[0] + dx, point[1]]\n",
    "                for point in block['points']\n",
    "            ]\n",
    "        }\n",
    "        for block in com_blocks\n",
    "    ]\n",
    "\n",
    "def bounds_to_width(bounds):\n",
    "    b_left = bounds[0]\n",
    "    b_right = bounds[2]\n",
    "    return b_right - b_left\n",
    "\n",
    "def com_blocks_overlap(com_blocks_points):\n",
    "    \"\"\"Return True of two com blocks overlaps.\"\"\"\n",
    "    if len(com_blocks_points & all_occupied_points) != 0:\n",
    "        return True\n",
    "    return False\n",
    "        \n",
    "def translate_to_fit(com_blocks, com_str, ds, dx_multiplier=1):\n",
    "    \"\"\"Take a block of points and transform their x-values to they fit in with existing blocks.\"\"\"\n",
    "    _com_blocks = com_blocks[:]\n",
    "    \n",
    "    i = 1\n",
    "    while True:\n",
    "        _com_blocks_points = all_points_in_blocks(_com_blocks, m=2)\n",
    "        overlaps = com_blocks_overlap(_com_blocks_points)\n",
    "        if overlaps:\n",
    "            dx = ds['coms'][com_str]['max_size'] / 2 * choice([-1, 1]) * i\n",
    "            print \"-- Overlaps --\",\n",
    "            print \"Moving block %d x-position --\" % dx\n",
    "            _com_blocks = translate_blocks(com_blocks, dx)\n",
    "        else:\n",
    "            x_pos = np.mean([_com_blocks[0]['points'][0][0], _com_blocks[0]['points'][-1][0]])\n",
    "            globals()['all_occupied_points'].update(_com_blocks_points)\n",
    "            x_vals = set([x for x, y in _com_blocks_points])\n",
    "            for x in np.arange(min(x_vals), max(x_vals)+1):\n",
    "                globals()['kernels'].append(x)\n",
    "            print \"Placing block at mean x-position %d\" % x_pos\n",
    "            print\n",
    "            return _com_blocks\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "def compute_similarity_matrix(communities):\n",
    "    def _get_similarity(i, j, communities):\n",
    "        \"\"\"communities : Communities in each layer\"\"\"\n",
    "        sim_counter = len(communities[i] & communities[j])\n",
    "        tot_counter = len(communities[i] | communities[j])\n",
    "        return sim_counter / float(tot_counter), sim_counter\n",
    "    \n",
    "    dim = max(communities.keys())\n",
    "    X = {}\n",
    "    for i in communities.keys():\n",
    "        for j in communities.keys():\n",
    "            sim, count = _get_similarity(i, j, communities)\n",
    "            try:\n",
    "                X['c' + str(i)].update({'c' + str(j): {'sim': sim, 'count': count}})\n",
    "            except KeyError:\n",
    "                X['c' + str(i)] = {'c' + str(j): {'sim': sim, 'count': count}}\n",
    "    return X\n",
    "\n",
    "def is_valid_location(new_block, existing_blocks, pad=5):\n",
    "    \"\"\"Check whether random horizontal location for block is unoccupied\"\"\"\n",
    "    nb_x = new_block['x']\n",
    "    nb_w = new_block['w']\n",
    "    nb_range = set(range(int(nb_x-pad),int(nb_x+nb_w+pad)))\n",
    "    for block in existing_blocks:\n",
    "        eb_x = block['x']\n",
    "        eb_w = block['w']\n",
    "        eb_range = set(range(int(eb_x-pad),int(eb_x+eb_w+pad)))\n",
    "        if len(nb_range & eb_range) != 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def participation_similarity(layer_commu):\n",
    "    \"\"\"Returns pairwise community participation profile cosine similarities.\"\"\"\n",
    "    # Count node participation for each community\n",
    "    all_nodes = set()\n",
    "    commu_participation_profile = defaultdict(Counter)\n",
    "    for l, layer_partition in layer_commu.items():\n",
    "        for c, nodes in layer_partition.items():\n",
    "            commu_participation_profile[c].update(nodes)\n",
    "            all_nodes.update(nodes)\n",
    "\n",
    "    # Compute pairwise cosine similarity of participation profiles\n",
    "    participation_vectors = np.array(\n",
    "        [\n",
    "            np.array([commu_participation_profile[c][n] for n in all_nodes])# * 1.0 / sum(commu_participation_profile[c].values())\n",
    "            for c in sorted(commu_participation_profile.keys())\n",
    "        ]\n",
    "    )\n",
    "    similarity_matrix = cosine_similarity(\n",
    "        participation_vectors\n",
    "    )\n",
    "    \n",
    "    # Extract upper triangle of similarity matrix\n",
    "    return [\n",
    "        similarity_matrix[i, j]\n",
    "        for i in range(similarity_matrix.shape[0])\n",
    "        for j in range(similarity_matrix.shape[1])\n",
    "        if j > i\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T22:19:51.243504Z",
     "start_time": "2017-10-08T22:19:50.947933Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# INPUT\n",
    "network = network2\n",
    "layer_communities = layer_commu_pred2_FC\n",
    "communities = communities_pred2_FC\n",
    "layer_indices = layer_indices2\n",
    "network_pajek = network_pajek2\n",
    "coupling_scheme = \"FC\"\n",
    "\n",
    "# Canvas parameters\n",
    "actual_height = len(network)\n",
    "min_group_size = 0\n",
    "\n",
    "# Set working width and height\n",
    "target_width = 1000\n",
    "height = actual_height\n",
    "\n",
    "\n",
    "#------#\n",
    "# Time #\n",
    "#------#\n",
    "\n",
    "layers_concat = pd.concat(network)\n",
    "\n",
    "# Start, termination, timestep variables\n",
    "#t0 = layers_concat['timestamp'].min() # 2014-02-03 00:05:00\n",
    "#tt = layers_concat['timestamp'].max() # 2014-02-04 00:00:00\n",
    "t0 = dt.combine(layers_concat['timestamp'].min().date(), dt.min.time())\n",
    "tt = dt.combine(layers_concat['timestamp'].max(), dt.max.time())\n",
    "\n",
    "d_t = str(5*fof) # 5 (minutes)\n",
    "\n",
    "thickness = 300 * fof  # 300 (seconds)\n",
    "\n",
    "# Lines marking important points in time\n",
    "grid_times = [time(h) for h in [8,12,13,17]]\n",
    "grid_ticks = dict(\n",
    "    (i+1, str(t0 + datetime.timedelta(seconds=thickness*(i+1))))\n",
    "    for i, l in enumerate(network) \n",
    "    if (t0 + datetime.timedelta(seconds=thickness*(i+1))).time() in grid_times\n",
    ")\n",
    "\n",
    "# Time tick labels\n",
    "label_times = [time(h) for h in range(24)]\n",
    "label_ticks = dict(\n",
    "    (i+1, str(t0 + datetime.timedelta(seconds=thickness*(i+1))))\n",
    "    for i, _ in enumerate(network) \n",
    "    if (t0 + datetime.timedelta(seconds=thickness*(i+1))).time() in label_times\n",
    ")\n",
    "\n",
    "#----------------------#\n",
    "# Build data structure #\n",
    "#----------------------#\n",
    "\n",
    "# Initiate data structure\n",
    "ds = {}\n",
    "\n",
    "# Meta\n",
    "ds['meta'] = {'w': None, 'h': height}\n",
    "\n",
    "# Time\n",
    "ds['time'] = {\n",
    "    't0': str(t0),\n",
    "    'tt': str(tt),\n",
    "    'dt': d_t,\n",
    "    'ticks': {\n",
    "        'label_ticks': label_ticks,\n",
    "        'grid_ticks': grid_ticks\n",
    "    }\n",
    "}\n",
    "\n",
    "# Community similarities\n",
    "ds['sims'] = compute_similarity_matrix(communities)\n",
    "\n",
    "# Initiate communities and layer networks\n",
    "ds['coms'] = {}\n",
    "ds['layer_networks'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T22:19:56.795639Z",
     "start_time": "2017-10-08T22:19:51.962940Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Community: 0\n",
      "Placing block at mean x-position 0\n",
      "\n",
      "\n",
      "Community: 1\n",
      "Placing block at mean x-position -394\n",
      "\n",
      "\n",
      "Community: 2\n",
      "Placing block at mean x-position 472\n",
      "\n",
      "\n",
      "Community: 3\n",
      "Placing block at mean x-position 217\n",
      "\n",
      "\n",
      "Community: 4\n",
      "Placing block at mean x-position -230\n",
      "\n",
      "\n",
      "Community: 5\n",
      "Placing block at mean x-position 61\n",
      "\n",
      "\n",
      "Community: 6\n",
      "Placing block at mean x-position -132\n",
      "\n",
      "\n",
      "Community: 7\n",
      "Placing block at mean x-position -467\n",
      "\n",
      "\n",
      "Community: 8\n",
      "Placing block at mean x-position 357\n",
      "\n",
      "\n",
      "Community: 9\n",
      "Placing block at mean x-position -287\n",
      "\n",
      "\n",
      "Community: 10\n",
      "Placing block at mean x-position -61\n",
      "\n",
      "\n",
      "Community: 11\n",
      "Placing block at mean x-position -452\n",
      "\n",
      "\n",
      "Community: 12\n",
      "Placing block at mean x-position -338\n",
      "\n",
      "\n",
      "Community: 13\n",
      "Placing block at mean x-position 155\n",
      "\n",
      "\n",
      "Community: 14\n",
      "Placing block at mean x-position 437\n",
      "\n",
      "\n",
      "Community: 15\n",
      "Placing block at mean x-position 106\n",
      "\n",
      "\n",
      "Community: 16\n",
      "Placing block at mean x-position -174\n",
      "\n",
      "\n",
      "Community: 17\n",
      "Placing block at mean x-position 383\n",
      "\n",
      "\n",
      "Community: 18\n",
      "Placing block at mean x-position 42\n",
      "\n",
      "\n",
      "Community: 19\n",
      "Placing block at mean x-position -16\n",
      "\n",
      "\n",
      "Community: 20\n",
      "Placing block at mean x-position 315\n",
      "\n",
      "\n",
      "Community: 21\n",
      "Placing block at mean x-position -356\n",
      "\n",
      "\n",
      "Community: 22\n",
      "-- Overlaps -- Moving block 2 x-position --\n",
      "-- Overlaps -- Moving block 4 x-position --\n",
      "-- Overlaps -- Moving block -6 x-position --\n",
      "-- Overlaps -- Moving block 8 x-position --\n",
      "-- Overlaps -- Moving block 10 x-position --\n",
      "-- Overlaps -- Moving block 12 x-position --\n",
      "-- Overlaps -- Moving block 14 x-position --\n",
      "Placing block at mean x-position -330\n",
      "\n",
      "\n",
      "Community: 23\n",
      "Placing block at mean x-position -198\n",
      "\n",
      "\n",
      "Community: 24\n",
      "-- Overlaps -- Moving block -1 x-position --\n",
      "-- Overlaps -- Moving block -2 x-position --\n",
      "-- Overlaps -- Moving block 3 x-position --\n",
      "-- Overlaps -- Moving block 4 x-position --\n",
      "-- Overlaps -- Moving block 5 x-position --\n",
      "-- Overlaps -- Moving block -6 x-position --\n",
      "Placing block at mean x-position -70\n",
      "\n",
      "\n",
      "Community: 25\n",
      "Placing block at mean x-position -42\n",
      "\n",
      "\n",
      "Community: 26\n",
      "Placing block at mean x-position 489\n",
      "\n",
      "\n",
      "Community: 27\n",
      "Placing block at mean x-position -253\n",
      "\n",
      "\n",
      "Community: 28\n",
      "Placing block at mean x-position 252\n",
      "\n",
      "\n",
      "Community: 29\n",
      "Placing block at mean x-position -31\n",
      "\n",
      "\n",
      "Community: 30\n",
      "Placing block at mean x-position -304\n",
      "\n",
      "\n",
      "Community: 31\n",
      "Placing block at mean x-position -214\n",
      "\n",
      "\n",
      "Community: 32\n",
      "Placing block at mean x-position 338\n",
      "\n",
      "\n",
      "Community: 33\n",
      "Placing block at mean x-position 203\n",
      "\n",
      "\n",
      "Community: 34\n",
      "Placing block at mean x-position 98\n",
      "\n",
      "\n",
      "Community: 35\n",
      "Placing block at mean x-position 280\n",
      "\n",
      "\n",
      "Community: 36\n",
      "Placing block at mean x-position 409\n",
      "\n",
      "\n",
      "Community: 37\n",
      "Placing block at mean x-position -238\n",
      "\n",
      "\n",
      "Community: 38\n",
      "Placing block at mean x-position -99\n",
      "\n",
      "\n",
      "Community: 39\n",
      "Placing block at mean x-position -317\n",
      "\n",
      "\n",
      "Community: 40\n",
      "Placing block at mean x-position -441\n",
      "\n",
      "\n",
      "Community: 41\n",
      "Placing block at mean x-position -493\n",
      "\n",
      "\n",
      "Community: 42\n",
      "Placing block at mean x-position 184\n",
      "\n",
      "\n",
      "Community: 43\n",
      "-- Overlaps -- Moving block -2 x-position --\n",
      "-- Overlaps -- Moving block -4 x-position --\n",
      "-- Overlaps -- Moving block -6 x-position --\n",
      "-- Overlaps -- Moving block 8 x-position --\n",
      "Placing block at mean x-position -51\n",
      "\n",
      "\n",
      "Community: 44\n",
      "Placing block at mean x-position -416\n",
      "\n",
      "\n",
      "Community: 45\n",
      "Placing block at mean x-position -274\n",
      "\n",
      "\n",
      "Community: 46\n",
      "Placing block at mean x-position 123\n",
      "\n",
      "\n",
      "Community: 47\n",
      "Placing block at mean x-position -291\n",
      "\n",
      "\n",
      "Community: 48\n",
      "Placing block at mean x-position 67\n",
      "\n",
      "\n",
      "Community: 49\n",
      "Placing block at mean x-position 55\n",
      "\n",
      "\n",
      "Community: 50\n",
      "Placing block at mean x-position -377\n",
      "\n",
      "\n",
      "Community: 51\n",
      "Placing block at mean x-position -410\n",
      "\n",
      "\n",
      "Community: 52\n",
      "-- Overlaps -- Moving block 1 x-position --\n",
      "Placing block at mean x-position 364\n",
      "\n",
      "\n",
      "Community: 53\n",
      "Placing block at mean x-position 366\n",
      "\n",
      "\n",
      "Community: 54\n",
      "Placing block at mean x-position 161\n",
      "\n",
      "\n",
      "Community: 55\n",
      "Placing block at mean x-position 455\n",
      "\n",
      "\n",
      "Community: 56\n",
      "Placing block at mean x-position -51\n",
      "\n",
      "\n",
      "Community: 57\n",
      "Placing block at mean x-position 279\n",
      "\n",
      "\n",
      "Community: 58\n",
      "Placing block at mean x-position -110\n",
      "\n",
      "\n",
      "Community: 59\n",
      "-- Overlaps -- Moving block 1 x-position --\n",
      "-- Overlaps -- Moving block -2 x-position --\n",
      "Placing block at mean x-position -403\n",
      "\n",
      "\n",
      "Community: 60\n",
      "Placing block at mean x-position 6\n",
      "\n",
      "\n",
      "Community: 61\n",
      "Placing block at mean x-position -149\n",
      "\n",
      "\n",
      "Community: 62\n",
      "Placing block at mean x-position 265\n",
      "\n",
      "\n",
      "Community: 63\n",
      "-- Overlaps -- Moving block -2 x-position --\n",
      "-- Overlaps -- Moving block -4 x-position --\n",
      "-- Overlaps -- Moving block 6 x-position --\n",
      "-- Overlaps -- Moving block -8 x-position --\n",
      "-- Overlaps -- Moving block -10 x-position --\n",
      "Placing block at mean x-position 462\n",
      "\n",
      "\n",
      "Community: 64\n",
      "Placing block at mean x-position 139\n",
      "\n",
      "\n",
      "Community: 65\n",
      "Placing block at mean x-position -274\n",
      "\n",
      "\n",
      "Community: 66\n",
      "Placing block at mean x-position -83\n",
      "\n",
      "\n",
      "Community: 67\n",
      "Placing block at mean x-position 322\n",
      "\n",
      "\n",
      "Community: 68\n",
      "Placing block at mean x-position -51\n",
      "\n",
      "\n",
      "Community: 69\n",
      "Placing block at mean x-position -206\n",
      "\n",
      "\n",
      "Community: 70\n",
      "Placing block at mean x-position 302\n",
      "\n",
      "\n",
      "Community: 71\n",
      "Placing block at mean x-position 146\n",
      "\n",
      "\n",
      "Community: 72\n",
      "Placing block at mean x-position -480\n",
      "\n",
      "\n",
      "Community: 73\n",
      "Placing block at mean x-position 472\n",
      "\n",
      "\n",
      "Community: 74\n",
      "Placing block at mean x-position -125\n",
      "\n",
      "\n",
      "Community: 75\n",
      "Placing block at mean x-position -51\n",
      "\n",
      "\n",
      "Community: 76\n",
      "Placing block at mean x-position -118\n",
      "\n",
      "\n",
      "Community: 77\n",
      "Placing block at mean x-position 96\n",
      "\n",
      "\n",
      "Community: 78\n",
      "Placing block at mean x-position 34\n",
      "\n",
      "\n",
      "Community: 79\n",
      "Placing block at mean x-position 248\n",
      "\n",
      "\n",
      "Community: 80\n",
      "Placing block at mean x-position 12\n",
      "\n",
      "\n",
      "Community: 81\n",
      "Placing block at mean x-position -240\n",
      "\n",
      "\n",
      "Community: 82\n",
      "Placing block at mean x-position -81\n",
      "\n",
      "\n",
      "Community: 83\n",
      "-- Overlaps -- Moving block 2 x-position --\n",
      "-- Overlaps -- Moving block -4 x-position --\n",
      "-- Overlaps -- Moving block -6 x-position --\n",
      "-- Overlaps -- Moving block 8 x-position --\n",
      "Placing block at mean x-position -30\n",
      "\n",
      "\n",
      "Community: 84\n",
      "Placing block at mean x-position 195\n",
      "\n",
      "\n",
      "Community: 85\n",
      "Placing block at mean x-position 206\n",
      "\n",
      "\n",
      "Community: 86\n",
      "Placing block at mean x-position -133\n",
      "\n",
      "\n",
      "Community: 87\n",
      "Placing block at mean x-position 120\n",
      "\n",
      "\n",
      "Community: 88\n",
      "Placing block at mean x-position 498\n",
      "\n",
      "\n",
      "Community: 89\n",
      "Placing block at mean x-position 432\n",
      "\n",
      "\n",
      "Community: 90\n",
      "Placing block at mean x-position -17\n",
      "\n",
      "\n",
      "Community: 91\n",
      "Placing block at mean x-position 299\n",
      "\n",
      "\n",
      "Community: 92\n",
      "-- Overlaps -- Moving block 1 x-position --\n",
      "-- Overlaps -- Moving block 2 x-position --\n",
      "-- Overlaps -- Moving block -3 x-position --\n",
      "-- Overlaps -- Moving block -4 x-position --\n",
      "-- Overlaps -- Moving block -5 x-position --\n",
      "-- Overlaps -- Moving block -6 x-position --\n",
      "-- Overlaps -- Moving block 7 x-position --\n",
      "Placing block at mean x-position -320\n",
      "\n",
      "\n",
      "Community: 93\n",
      "Placing block at mean x-position 182\n",
      "\n",
      "\n",
      "Community: 94\n",
      "Placing block at mean x-position 68\n",
      "\n",
      "\n",
      "Community: 95\n",
      "Placing block at mean x-position -123\n",
      "\n",
      "\n",
      "Community: 96\n",
      "Placing block at mean x-position 342\n",
      "\n",
      "\n",
      "Community: 97\n",
      "Placing block at mean x-position -33\n",
      "\n",
      "\n",
      "Community: 98\n",
      "Placing block at mean x-position 242\n",
      "\n",
      "\n",
      "Community: 99\n",
      "Placing block at mean x-position 351\n",
      "\n",
      "\n",
      "Community: 100\n",
      "Placing block at mean x-position 486\n",
      "\n",
      "\n",
      "Community: 101\n",
      "Placing block at mean x-position -169\n",
      "\n",
      "\n",
      "Community: 102\n",
      "Placing block at mean x-position -111\n",
      "\n",
      "\n",
      "Community: 103\n",
      "Placing block at mean x-position 112\n",
      "\n",
      "\n",
      "Community: 104\n",
      "Placing block at mean x-position 192\n",
      "\n",
      "\n",
      "Community: 105\n",
      "Placing block at mean x-position 125\n",
      "\n",
      "\n",
      "Community: 106\n",
      "Placing block at mean x-position 273\n",
      "\n",
      "\n",
      "Community: 107\n",
      "Placing block at mean x-position 145\n",
      "\n",
      "\n",
      "Community: 108\n",
      "Placing block at mean x-position -257\n",
      "\n",
      "\n",
      "Community: 109\n",
      "Placing block at mean x-position 197\n",
      "\n",
      "\n",
      "Community: 110\n",
      "-- Overlaps -- Moving block -1 x-position --\n",
      "-- Overlaps -- Moving block 2 x-position --\n",
      "-- Overlaps -- Moving block 3 x-position --\n",
      "-- Overlaps -- Moving block -4 x-position --\n",
      "-- Overlaps -- Moving block -5 x-position --\n",
      "-- Overlaps -- Moving block -6 x-position --\n",
      "-- Overlaps -- Moving block 7 x-position --\n",
      "-- Overlaps -- Moving block -8 x-position --\n",
      "Placing block at mean x-position 270\n",
      "\n",
      "\n",
      "Community: 111\n",
      "Placing block at mean x-position 142\n",
      "\n",
      "\n",
      "Community: 112\n",
      "Placing block at mean x-position 47\n",
      "\n",
      "\n",
      "Community: 113\n",
      "Placing block at mean x-position -95\n",
      "\n",
      "\n",
      "Community: 114\n",
      "Placing block at mean x-position -404\n",
      "\n",
      "\n",
      "Community: 115\n",
      "Placing block at mean x-position 352\n",
      "\n",
      "\n",
      "Community: 116\n",
      "Placing block at mean x-position -96\n",
      "\n",
      "\n",
      "Community: 117\n",
      "Placing block at mean x-position 110\n",
      "\n",
      "\n",
      "Community: 118\n",
      "Placing block at mean x-position -212\n",
      "\n",
      "\n",
      "Community: 119\n",
      "Placing block at mean x-position 442\n",
      "\n",
      "\n",
      "Community: 120\n",
      "Placing block at mean x-position -243\n",
      "\n",
      "\n",
      "Community: 121\n",
      "Placing block at mean x-position 10\n",
      "\n",
      "\n",
      "Community: 122\n",
      "Placing block at mean x-position -425\n",
      "\n",
      "\n",
      "Community: 123\n",
      "Placing block at mean x-position -264\n",
      "\n",
      "\n",
      "Community: 124\n",
      "Placing block at mean x-position 485\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Community: 125\n",
      "Placing block at mean x-position 158\n",
      "\n",
      "\n",
      "Community: 126\n",
      "Placing block at mean x-position -299\n",
      "\n",
      "\n",
      "Community: 127\n",
      "Placing block at mean x-position -407\n",
      "\n",
      "\n",
      "Community: 128\n",
      "Placing block at mean x-position 227\n",
      "\n",
      "\n",
      "Community: 129\n",
      "Placing block at mean x-position 258\n",
      "\n",
      "\n",
      "Community: 130\n",
      "Placing block at mean x-position 77\n",
      "\n",
      "\n",
      "Community: 131\n",
      "Placing block at mean x-position -367\n",
      "\n",
      "\n",
      "Community: 132\n",
      "Placing block at mean x-position -103\n",
      "\n",
      "\n",
      "Community: 133\n",
      "-- Overlaps -- Moving block 1 x-position --\n",
      "-- Overlaps -- Moving block -2 x-position --\n",
      "-- Overlaps -- Moving block 3 x-position --\n",
      "-- Overlaps -- Moving block 4 x-position --\n",
      "-- Overlaps -- Moving block -5 x-position --\n",
      "-- Overlaps -- Moving block -6 x-position --\n",
      "-- Overlaps -- Moving block -7 x-position --\n",
      "Placing block at mean x-position 465\n",
      "\n",
      "\n",
      "Community: 134\n",
      "Placing block at mean x-position -181\n",
      "\n",
      "\n",
      "Community: 135\n",
      "Placing block at mean x-position 143\n",
      "\n",
      "\n",
      "Community: 136\n",
      "Placing block at mean x-position -254\n",
      "\n",
      "\n",
      "Community: 137\n",
      "Placing block at mean x-position 165\n",
      "\n",
      "\n",
      "Community: 138\n",
      "Placing block at mean x-position 167\n",
      "\n",
      "\n",
      "Community: 139\n",
      "Placing block at mean x-position 136\n",
      "\n",
      "\n",
      "Community: 140\n",
      "Placing block at mean x-position -255\n",
      "\n",
      "\n",
      "Community: 141\n",
      "Placing block at mean x-position -449\n",
      "\n",
      "\n",
      "Community: 142\n",
      "Placing block at mean x-position 95\n",
      "\n",
      "\n",
      "Community: 143\n",
      "Placing block at mean x-position -141\n",
      "\n",
      "\n",
      "Community: 144\n",
      "Placing block at mean x-position 111\n",
      "\n",
      "\n",
      "Community: 145\n",
      "Placing block at mean x-position -376\n",
      "\n",
      "\n",
      "Community: 146\n",
      "Placing block at mean x-position 443\n",
      "\n",
      "\n",
      "Community: 147\n",
      "Placing block at mean x-position -77\n",
      "\n",
      "\n",
      "Community: 148\n",
      "Placing block at mean x-position 317\n",
      "\n",
      "\n",
      "Community: 149\n",
      "Placing block at mean x-position -498\n",
      "\n",
      "\n",
      "Community: 150\n",
      "Placing block at mean x-position -281\n",
      "\n",
      "\n",
      "Community: 151\n",
      "-- Overlaps -- Moving block -1 x-position --\n",
      "-- Overlaps -- Moving block 2 x-position --\n",
      "Placing block at mean x-position 104\n",
      "\n",
      "\n",
      "Community: 152\n",
      "Placing block at mean x-position 276\n",
      "\n",
      "\n",
      "Community: 153\n",
      "Placing block at mean x-position 381\n",
      "\n",
      "\n",
      "Community: 154\n",
      "-- Overlaps -- Moving block 1 x-position --\n",
      "-- Overlaps -- Moving block 2 x-position --\n",
      "-- Overlaps -- Moving block -3 x-position --\n",
      "-- Overlaps -- Moving block 4 x-position --\n",
      "Placing block at mean x-position 70\n",
      "\n",
      "\n",
      "Community: 155\n",
      "Placing block at mean x-position -88\n",
      "\n",
      "\n",
      "Community: 156\n",
      "-- Overlaps -- Moving block 1 x-position --\n",
      "-- Overlaps -- Moving block -2 x-position --\n",
      "-- Overlaps -- Moving block 3 x-position --\n",
      "-- Overlaps -- Moving block -4 x-position --\n",
      "-- Overlaps -- Moving block 5 x-position --\n",
      "-- Overlaps -- Moving block 6 x-position --\n",
      "-- Overlaps -- Moving block 7 x-position --\n",
      "Placing block at mean x-position 323\n",
      "\n",
      "\n",
      "Community: 157\n",
      "Placing block at mean x-position 285\n",
      "\n",
      "\n",
      "Community: 158\n",
      "Placing block at mean x-position 59\n",
      "\n",
      "\n",
      "Community: 159\n",
      "Placing block at mean x-position -352\n",
      "\n",
      "\n",
      "Community: 160\n",
      "Placing block at mean x-position 427\n",
      "\n",
      "\n",
      "Community: 161\n",
      "Placing block at mean x-position 319\n",
      "\n",
      "\n",
      "Community: 162\n",
      "Placing block at mean x-position -148\n",
      "\n",
      "\n",
      "Community: 163\n",
      "Placing block at mean x-position 274\n",
      "\n",
      "\n",
      "Community: 164\n",
      "Placing block at mean x-position 369\n",
      "\n",
      "\n",
      "Community: 165\n",
      "Placing block at mean x-position 18\n",
      "\n",
      "\n",
      "Community: 166\n",
      "Placing block at mean x-position 395\n",
      "\n",
      "\n",
      "Community: 167\n",
      "Placing block at mean x-position -221\n",
      "\n",
      "\n",
      "Community: 168\n",
      "-- Overlaps -- Moving block 1 x-position --\n",
      "-- Overlaps -- Moving block 2 x-position --\n",
      "-- Overlaps -- Moving block -3 x-position --\n",
      "-- Overlaps -- Moving block 4 x-position --\n",
      "-- Overlaps -- Moving block -5 x-position --\n",
      "-- Overlaps -- Moving block -6 x-position --\n",
      "-- Overlaps -- Moving block -7 x-position --\n",
      "-- Overlaps -- Moving block 8 x-position --\n",
      "Placing block at mean x-position -383\n",
      "\n",
      "\n",
      "Community: 169\n",
      "Placing block at mean x-position 411\n",
      "\n",
      "\n",
      "Community: 170\n",
      "Placing block at mean x-position -486\n",
      "\n",
      "\n",
      "Community: 171\n",
      "Placing block at mean x-position 193\n",
      "\n",
      "\n",
      "Community: 172\n",
      "Placing block at mean x-position -242\n",
      "\n",
      "\n",
      "Community: 173\n",
      "Placing block at mean x-position 254\n",
      "\n",
      "\n",
      "Community: 174\n",
      "Placing block at mean x-position 276\n",
      "\n",
      "\n",
      "Community: 175\n",
      "Placing block at mean x-position 37\n",
      "\n",
      "\n",
      "Community: 176\n",
      "Placing block at mean x-position -336\n",
      "\n",
      "\n",
      "Community: 177\n",
      "Placing block at mean x-position -162\n",
      "\n",
      "\n",
      "Community: 178\n",
      "Placing block at mean x-position -435\n",
      "\n",
      "\n",
      "Community: 179\n",
      "Placing block at mean x-position 455\n",
      "\n",
      "\n",
      "Community: 180\n",
      "Placing block at mean x-position -322\n",
      "\n",
      "\n",
      "Community: 181\n",
      "-- Overlaps -- Moving block 1 x-position --\n",
      "-- Overlaps -- Moving block -2 x-position --\n",
      "-- Overlaps -- Moving block -3 x-position --\n",
      "-- Overlaps -- Moving block 4 x-position --\n",
      "-- Overlaps -- Moving block -5 x-position --\n",
      "-- Overlaps -- Moving block 6 x-position --\n",
      "-- Overlaps -- Moving block -7 x-position --\n",
      "-- Overlaps -- Moving block -8 x-position --\n",
      "-- Overlaps -- Moving block 9 x-position --\n",
      "-- Overlaps -- Moving block 10 x-position --\n",
      "-- Overlaps -- Moving block 11 x-position --\n",
      "-- Overlaps -- Moving block 12 x-position --\n",
      "-- Overlaps -- Moving block -13 x-position --\n",
      "Placing block at mean x-position 347\n",
      "\n",
      "\n",
      "Community: 182\n",
      "Placing block at mean x-position -440\n",
      "\n",
      "\n",
      "Community: 183\n",
      "Placing block at mean x-position 264\n",
      "\n",
      "\n",
      "Community: 184\n",
      "Placing block at mean x-position -221\n",
      "\n",
      "\n",
      "Community: 185\n",
      "Placing block at mean x-position 340\n",
      "\n",
      "\n",
      "Community: 186\n",
      "Placing block at mean x-position -74\n",
      "\n",
      "\n",
      "Community: 187\n",
      "-- Overlaps -- Moving block -1 x-position --\n",
      "-- Overlaps -- Moving block 2 x-position --\n",
      "-- Overlaps -- Moving block -3 x-position --\n",
      "-- Overlaps -- Moving block 4 x-position --\n",
      "-- Overlaps -- Moving block 5 x-position --\n",
      "-- Overlaps -- Moving block 6 x-position --\n",
      "Placing block at mean x-position 69\n",
      "\n",
      "\n",
      "Community: 188\n",
      "-- Overlaps -- Moving block -1 x-position --\n",
      "-- Overlaps -- Moving block 2 x-position --\n",
      "-- Overlaps -- Moving block -3 x-position --\n",
      "-- Overlaps -- Moving block -4 x-position --\n",
      "-- Overlaps -- Moving block 5 x-position --\n",
      "-- Overlaps -- Moving block -6 x-position --\n",
      "Placing block at mean x-position 356\n",
      "\n",
      "\n",
      "Community: 189\n",
      "Placing block at mean x-position 28\n",
      "\n",
      "\n",
      "Community: 190\n",
      "-- Overlaps -- Moving block -1 x-position --\n",
      "-- Overlaps -- Moving block 2 x-position --\n",
      "-- Overlaps -- Moving block -3 x-position --\n",
      "-- Overlaps -- Moving block 4 x-position --\n",
      "Placing block at mean x-position -221\n",
      "\n",
      "\n",
      "Community: 191\n",
      "Placing block at mean x-position -163\n",
      "\n",
      "\n",
      "Community: 192\n",
      "Placing block at mean x-position -100\n",
      "\n",
      "\n",
      "Community: 193\n",
      "Placing block at mean x-position -255\n",
      "\n",
      "\n",
      "Community: 194\n",
      "Placing block at mean x-position 477\n",
      "\n",
      "\n",
      "Community: 195\n",
      "Placing block at mean x-position 364\n",
      "\n",
      "\n",
      "Community: 196\n",
      "Placing block at mean x-position -118\n",
      "\n",
      "\n",
      "Community: 197\n",
      "Placing block at mean x-position -75\n",
      "\n",
      "\n",
      "Community: 198\n",
      "Placing block at mean x-position -167\n",
      "\n",
      "\n",
      "Community: 199\n",
      "Placing block at mean x-position -332\n",
      "\n",
      "\n",
      "Community: 200\n",
      "Placing block at mean x-position 386\n",
      "\n",
      "\n",
      "Community: 201\n",
      "Placing block at mean x-position 330\n",
      "\n",
      "\n",
      "Community: 202\n",
      "-- Overlaps -- Moving block -1 x-position --\n",
      "-- Overlaps -- Moving block 2 x-position --\n",
      "-- Overlaps -- Moving block -3 x-position --\n",
      "-- Overlaps -- Moving block -4 x-position --\n",
      "-- Overlaps -- Moving block -5 x-position --\n",
      "-- Overlaps -- Moving block -6 x-position --\n",
      "Placing block at mean x-position 376\n",
      "\n",
      "\n",
      "Community: 203\n",
      "Placing block at mean x-position -79\n",
      "\n",
      "\n",
      "Community: 204\n",
      "Placing block at mean x-position 50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get communities\n",
    "community_ids = set()\n",
    "for _, coms in layer_communities.items():\n",
    "    community_ids.update(coms.keys())\n",
    "    \n",
    "# Initiate all occupied points\n",
    "all_occupied_points = set()\n",
    "kernels = []\n",
    "\n",
    "# Loop over communities build blocks\n",
    "for com in (community_ids):\n",
    "    \n",
    "    com_str =  \"c\" + str(com)\n",
    "    \n",
    "    ds['coms'][com_str] = {}\n",
    "    ds['coms'][com_str]['blocks'] = []\n",
    "    ds['coms'][com_str]['duration'] = 0\n",
    "    ds['coms'][com_str]['abs_size'] = len(communities[com])\n",
    "    ds['coms'][com_str]['min_size'] = np.inf\n",
    "    ds['coms'][com_str]['max_size'] = 1\n",
    "    ds['coms'][com_str]['avg_size'] = []\n",
    "    \n",
    "    if len(kernels) > 0:\n",
    "        X = np.array(kernels).reshape((-1, 1))\n",
    "        kde = KernelDensity(kernel='gaussian', bandwidth=3).fit(X)\n",
    "        X_grid = np.arange(-target_width/2, target_width/2)\n",
    "        X_scores = kde.score_samples(X_grid.reshape((-1, 1))).reshape((1, -1))[0]\n",
    "        X_scores = -np.array(X_scores)\n",
    "        X_scores = X_scores / np.sum(X_scores)\n",
    "        dx0_index = np.random.choice(range(len(X_grid)), 1, p=X_scores)[0]\n",
    "        dx0 = X_grid[dx0_index]\n",
    "    else:\n",
    "        dx0 = 0\n",
    "        \n",
    "    \n",
    "    print \"\\nCommunity:\", com\n",
    "    #print \"Layer:\",\n",
    "    # Compute all points for 'com'\n",
    "    com_blocks = []\n",
    "    prev_l = -2\n",
    "    for l, coms in layer_communities.items():\n",
    "        \n",
    "        # Skip layers where com is not present\n",
    "        if com not in coms: continue\n",
    "        #print l,\n",
    "        # Start new block if com was not in previous layer\n",
    "        if l != prev_l + 1:\n",
    "            if prev_l != -2: \n",
    "                ds['coms'][com_str]['blocks'].append({\n",
    "                    'c': com_str,                     # Append block to com_blocks after removing points.\n",
    "                    'points': ordered_set(block)  # If there is a graphics bug, try removing the above line\n",
    "                })\n",
    "            block = []\n",
    "            \n",
    "        # Width of community in layer l\n",
    "        com_width = len(coms[com])\n",
    "        \n",
    "        if com_width < ds['coms'][com_str]['min_size']: ds['coms'][com_str]['min_size'] = com_width\n",
    "        if com_width > ds['coms'][com_str]['max_size']: ds['coms'][com_str]['max_size'] = com_width\n",
    "        ds['coms'][com_str]['avg_size'].append(com_width)\n",
    "        ds['coms'][com_str]['duration'] += 60 * thickness\n",
    "        \n",
    "        points = [\n",
    "            [-com_width / 2.0 + dx0, l - 1],\n",
    "            [com_width / 2.0 + dx0, l - 1],\n",
    "            [-com_width / 2.0 + dx0, l],\n",
    "            [com_width / 2.0 + dx0, l]\n",
    "        ]\n",
    "        \n",
    "        # Insert points in middle of block to create clockwise polygon points\n",
    "        for p in points:\n",
    "            block.insert(len(block) / 2, p)\n",
    "        \n",
    "        # Store number of previous layer\n",
    "        prev_l = l\n",
    "        \n",
    "    else:\n",
    "        ds['coms'][com_str]['blocks'].append({\n",
    "            'c': com_str,                     # Append block to com_blocks after removing points.\n",
    "            'points': ordered_set(block)  # If there is a graphics bug, try removing the above line\n",
    "        })\n",
    "    \n",
    "    #print \"\\nAdding block where it fits\",\n",
    "    # Add the x-position corrected block to a temporary datastructure\n",
    "    ds['coms'][com_str]['blocks'] = translate_to_fit(ds['coms'][com_str]['blocks'], com_str, ds, dx_multiplier=1)\n",
    "    ds['coms'][com_str]['avg_size'] = float(\"%.02f\" % np.mean(ds['coms'][com_str]['avg_size']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T22:19:56.819232Z",
     "start_time": "2017-10-08T22:19:56.797715Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Add colors\n",
    "# Deprecated: is still needed on script. Misleading that it is not namechanged or something.\n",
    "com_cols = {}\n",
    "for com in ds['coms'].keys():\n",
    "    r = np.average([mmh3.hash(str(n))%256 for n in communities[int(com[1:])]])\n",
    "    g = np.average([mmh3.hash(str(n))%255 for n in communities[int(com[1:])]])\n",
    "    b = np.average([mmh3.hash(str(n))%254 for n in communities[int(com[1:])]])\n",
    "    com_cols[com] = 'rgb(%d,%d,%d)' % (r,g,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T22:19:56.852288Z",
     "start_time": "2017-10-08T22:19:56.822258Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "xx = []\n",
    "for com in ds['coms'].keys():\n",
    "    for block in ds['coms'][com]['blocks']:\n",
    "        for point in block['points']:\n",
    "            xx.append(point[0])\n",
    "\n",
    "ds['meta']['w'] = max(xx) - min(xx)\n",
    "for com_str in ds['coms'].keys():\n",
    "    ds['coms'][com_str]['blocks'] = translate_blocks(ds['coms'][com_str]['blocks'], -min(xx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T22:19:57.020183Z",
     "start_time": "2017-10-08T22:19:56.854791Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Add networks\n",
    "def layer_networks(network_pajek, layer_communities, layer_indices=None):\n",
    "    \n",
    "    if layer_indices is None:\n",
    "        layer_indices = dict((l, l) for l in layer_communities.keys())\n",
    "    \n",
    "    rawstring_nodes = network_pajek.split(\"*\")[1:2][0]\n",
    "    rawstring_edges = network_pajek.split(\"*\")[2:3][0]\n",
    "    rawstring = \"\"  # Clear\n",
    "    \n",
    "    # Get nodes\n",
    "    nodes_map = dict(\n",
    "        (int(n.split()[0]), int(n.split('\"')[1]))\n",
    "        for n in re.findall(r'\\d+ \".+?\".*?\\n', rawstring_nodes)\n",
    "    )\n",
    "    nodes_map_reverse = dict((v,k) for k,v in nodes_map.items())\n",
    "    rawstring_nodes = \"\"  # Clear\n",
    "    \n",
    "    ln = {'data': {}}\n",
    "    \n",
    "    e_li = [e[0:1] + e[1:2] + e[0:1] + e[2:] for e in [e_str.split() for e_str in rawstring_edges.split('\\n')[2:]]]\n",
    "    rawstring_edges = \"\"  # Clear\n",
    "    \n",
    "    # Add edges, one at a time\n",
    "    for e in e_li:\n",
    "        if e == []:\n",
    "            continue\n",
    "        layer, source, target, value = layer_indices[int(e[0])], int(e[1]), int(e[3]), int(float(e[4]))\n",
    "        try:\n",
    "            node = source; source_target_err = \"source\"\n",
    "            group_source = [g for g, n in layer_communities[layer].items() if nodes_map[source] in n][0]\n",
    "            node = target; source_target_err = \"target\"\n",
    "            group_target = [g for g, n in layer_communities[layer].items() if nodes_map[target] in n][0]\n",
    "        except IndexError:\n",
    "            # This occurs if the source/target has no group, WHICH IT SHOULD. Why this happend (and it\n",
    "            # very rarely does) I don't know, maybe it's something with Infomap.\n",
    "            print source_target_err, \"node\", node, \"has no group in layer\", layer, \"... skipping link!\"\n",
    "            continue\n",
    "        except KeyError:\n",
    "            # This occurs if there's a node parsed by the Infomap function which was not parsed to the\n",
    "            # nodes map. Typically this is because I set Infomap to parse from the output pajek file\n",
    "            # and the nodes map to be parsed from the input.\n",
    "            print \"node\", source, \"or\", target, \"could not be parsed in layer\", layer, \"... skipping link!\"\n",
    "            \n",
    "        if \"c\"+str(group_source) not in com_cols or \"c\"+str(group_target) not in com_cols:\n",
    "            continue\n",
    "    \n",
    "        edge = {'source': source, 'target': target, 'value': value/10.0}\n",
    "        try:\n",
    "            ln['data'][layer]['links'].append(edge)\n",
    "        except KeyError:\n",
    "            ln['data'][layer] = {'links': [edge]}\n",
    "        \n",
    "        for n1, n2 in [(source, target),(target, source)]:\n",
    "            try:\n",
    "                ln['data'][layer]['links_dict'][n1].append(n2)\n",
    "            except KeyError:\n",
    "                try:\n",
    "                    ln['data'][layer]['links_dict'][n1] = [n2]\n",
    "                except KeyError:\n",
    "                    ln['data'][layer]['links_dict'] = {n1: [n2]}\n",
    "                \n",
    "    e_li = []  # Clear\n",
    "    \n",
    "    # Add nodes\n",
    "    for layer, edges_and_nodes in ln['data'].items():\n",
    "        edges = edges_and_nodes['links']\n",
    "        nodes_names = set()\n",
    "        for e in edges:\n",
    "            nodes_names.add(e['source'])\n",
    "            nodes_names.add(e['target'])\n",
    "        nodes = []\n",
    "        for nn in nodes_names:\n",
    "            group = [g for g,n in layer_communities[layer].items()\n",
    "                         if nodes_map[nn] in n][0]\n",
    "            try:\n",
    "                col = com_cols['c'+str(group)]\n",
    "            except KeyError:\n",
    "                #col = 'rgb(%d,%d,%d)' % (200,200,200)\n",
    "                continue\n",
    "            node = {'name': nn, 'id': nodes_map[nn], 'group': group}\n",
    "            try:\n",
    "                ln['data'][layer]['nodes'][nn] = node\n",
    "            except KeyError:\n",
    "                ln['data'][layer].update({'nodes': {nn: node}})\n",
    "                \n",
    "            try:\n",
    "                ln['data'][layer]['groups'][group].append(node['name'])\n",
    "            except KeyError:\n",
    "                try:\n",
    "                    ln['data'][layer]['groups'][group] = [node['name']]\n",
    "                except KeyError:\n",
    "                    ln['data'][layer]['groups'] = {group: [node['name']]}\n",
    "    \n",
    "    return ln\n",
    "\n",
    "ds['layer_networks'] = layer_networks(network_pajek, layer_communities, layer_indices=layer_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T22:20:03.915142Z",
     "start_time": "2017-10-08T22:20:03.121607Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def parse_datetime(t):\n",
    "    return dt.strptime(t, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "def translate_blocks2(v, dl, day_layers, deltatime):\n",
    "    _v = v.copy()\n",
    "    p1_all = set()\n",
    "    _v['blocks'] = []\n",
    "    for b in v['blocks']:\n",
    "        block = {'c': b['c'], 'points': []}\n",
    "        for p in b['points']:\n",
    "            if p[1] in day_layers:\n",
    "                p1_new = p[1] + dl\n",
    "                p1_all.add(p1_new)\n",
    "                block['points'].append([p[0], p1_new])\n",
    "        if len(block['points']) > 0:\n",
    "            _v['blocks'].append(block)\n",
    "    _v['duration'] = deltatime * (max(p1_all) - min(p1_all)) * 60\n",
    "    return _v\n",
    "\n",
    "time_delta = (parse_datetime(ds['time']['tt'].split(\".\")[0]) - parse_datetime(ds['time']['t0'].split(\".\")[0]))\n",
    "num_days = time_delta.days + np.int(np.round(time_delta.seconds * 1.0 / 86400))\n",
    "layers_per_day = 86400 / (int(ds['time']['dt']) * 60)\n",
    "weekday_labels = [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\n",
    "\n",
    "for day in range(num_days):\n",
    "    ds_tmp = {}\n",
    "    \n",
    "    # Get layers and communities that happen in this day\n",
    "    day_layer_min, day_layer_max = layers_per_day*day, layers_per_day*(day+1)\n",
    "    day_layers = range(day_layer_min, day_layer_max)\n",
    "    day_layers_non_empty = sorted([l for l in layer_communities.keys() if day_layer_min <= l < day_layer_max])\n",
    "    day_communities = set([\n",
    "        'c'+str(g)  # Maybe add 1\n",
    "        for l in day_layers_non_empty\n",
    "        for g in ds['layer_networks']['data'][l]['groups'].keys()\n",
    "    ])\n",
    "    \n",
    "    # Community similarities\n",
    "    ds_tmp['sims'] = dict(\n",
    "        (k, dict((_k, _v) for _k, _v in v.items() if _k in day_communities))\n",
    "        for k, v in ds['sims'].items()\n",
    "        if k in day_communities\n",
    "    )\n",
    "    \n",
    "    # Community geometry data\n",
    "    ds_tmp['coms'] = dict(\n",
    "        (k, translate_blocks2(v, -day*layers_per_day, day_layers, int(ds['time']['dt'])))\n",
    "        for k, v in ds['coms'].items()\n",
    "        if k in day_communities\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Layer network data\n",
    "    ds_tmp['layer_networks'] = dict()\n",
    "    ds_tmp['layer_networks']['data'] = dict(\n",
    "        (k-day*layers_per_day, v)\n",
    "        for k, v in ds['layer_networks']['data'].items()\n",
    "        if k in day_layers\n",
    "    )\n",
    "    \n",
    "    # Time data\n",
    "    ds_tmp['time'] = dict()\n",
    "    ds_tmp['time']['dt'] = ds['time']['dt']\n",
    "    ds_tmp['time']['t0'] = str(parse_datetime(ds['time']['t0']) + datetime.timedelta(days=day))\n",
    "    ds_tmp['time']['tt'] = str(parse_datetime(ds['time']['t0']) + datetime.timedelta(days=(day+1)))\n",
    "    ds_tmp['time']['ticks'] = dict()\n",
    "    ds_tmp['time']['ticks']['grid_ticks'] = dict(\n",
    "        (k-day*layers_per_day, v)\n",
    "        for k, v in ds['time']['ticks']['grid_ticks'].items()\n",
    "        if k in day_layers\n",
    "    )\n",
    "    ds_tmp['time']['ticks']['label_ticks'] = dict(\n",
    "        (k-day*layers_per_day, v)\n",
    "        for k, v in ds['time']['ticks']['label_ticks'].items()\n",
    "        if k in day_layers\n",
    "    )\n",
    "    \n",
    "    # Metadata\n",
    "    ds_tmp['meta'] = {'h': len(day_layers), 'w': ds['meta']['w']}\n",
    "    \n",
    "    with open('Visualisation/data_workplace_%s/dataset%s.json' % (coupling_scheme, weekday_labels[day]), 'w') as outfile:\n",
    "        json.dump(ds_tmp, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
